export default class LLMChatContext {

    model = "llama"
    temperature = 0.8


}